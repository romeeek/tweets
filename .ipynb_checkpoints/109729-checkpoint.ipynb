{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Angry Tweets\n",
    "\n",
    "Celem zadania było odkrycie nastroju jaki panuje w małym poscie, zwanym 'tweetem'. Może on należeć do jednej z trzech klas: pozytywnej, neutralnej bądź negatywnej. W celu wykonania tego zadania posłużono się językiem Python oraz pakietem scikit-learn. \n",
    "\n",
    "Dane treningowe znajdują się w 'train.csv', który zawiera 5970 wierszy i trzy kolumny: 'Id', 'Category' oraz 'Tweet'. Plik z danymi testowymi posiada 4000 wierszy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pobranie danych i ich przetwarzanie.\n",
    "\n",
    "Pierwszy krok to wczytanie niezbędnych bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dane są pobierane z pliku csv do zmiennej 'tweetSet'. W tym celu wykorzystywana jest funkcja read_csv z pakietu pandas. Przy pomocy np.rand, dane są dzielone na zbiór treningowy i testowy w odpowiednim stosunku 70/30. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def splitData(dataSet, prop):\n",
    "    r = np.random.rand(len(dataSet)) < prop\n",
    "    return dataSet[r], dataSet[~r]     \n",
    "\n",
    "tweetsSet= pd.read_csv(\"train.csv\",sep=',', header = 1, names=['Id','Category','Tweet'])\n",
    "tweetTrain, tweetTest = splitData(tweetsSet, 0.7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W pętlach w funkcji prepareAndCleanData() usuwane są z tweeta słowa zaczynające się na @, ponieważ są one wskaźnikiem na innego użytkownika serwisu oraz wszystkie linki do innych stron. Dodatkowo zostały usunięte wszystkie emotiknony. Te wyrażenia nie oddają nam klasy postu. Na samym koncu pętli do zmiennych *data* oraz *label* dodajemy odpowiednio zmodyfikowaną zawartość tweeta oraz jego klasę."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepareAndCleanData(tweets):\n",
    "    data = []\n",
    "    label = []\n",
    "    for index, tweet in tweets.iterrows():\n",
    "        tweet['Tweet'] = re.sub(r'@\\w+', '', tweet['Tweet'])\n",
    "        tweet['Tweet'] = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', tweet['Tweet'])\n",
    "        tweet['Tweet'] = re.sub(\"(:-?\\))|(:p)|(:d+)|(:-?\\()|(:/)|(;-?\\))|(<3)|(=\\))|(\\)-?:)|(:'\\()|(8\\))\", '', tweet['Tweet'])\n",
    "        data.append(tweet['Tweet'])\n",
    "        label.append(tweet['Category'])\n",
    "    return data, label\n",
    "\n",
    "tweetTrainData, tweetTrainLabel = prepareAndCleanData(tweetTrain)\n",
    "tweetTestData, tweetTestLabel = prepareAndCleanData(tweetTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przed klasyfikacja, treść tweetów została przekonwertowana do macierzy TF-IDF. W tym celu użyto funkcji TfidfVectorizer z pakietu **scikit-learn**. Przy pomocy poniższych parametrów została ona dostrojona:\n",
    "- **min_df** - słowa występujące mniej niż 5 razy są odrzucone,\n",
    "- **max_df** - termy ukazuące się w ponad 75% dokumnetów nie są brane pod uwagę,\n",
    "- **sublinear_tf** - domyślnie wartość False, skaluje ona wartość *tf* na *1+log(tf)*\n",
    "- **stop_words** - lista słów, która nie jest usuwana.\n",
    "\n",
    "Następnie tworzona jest macierz słowo-dokument. Na samym końcu jest ona zamienia do interesującej nas postaci macierzy dokument-term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def buildDocumentTermMatrix(trainData, testData):\n",
    "    stopWords = [\"a\",\"able\",\"about\",\"across\",\"after\",\"all\",\"almost\",\"also\",\"am\",\"among\",\"an\",\"and\",\"any\",\"are\",\"as\",\"at\",\"be\",\"because\",\"been\",\"but\",\"by\",\"can\",\"cannot\",\"could\",\"dear\",\"did\",\"do\",\"does\",\"either\",\"else\",\"ever\",\"every\",\"for\",\"from\",\"get\",\"got\",\"had\",\"has\",\"have\",\"he\",\"her\",\"hers\",\"him\",\"his\",\"how\",\"however\",\"i\",\"if\",\"in\",\"into\",\"is\",\"it\",\"its\",\"just\",\"least\",\"let\",\"like\",\"likely\",\"may\",\"me\",\"might\",\"most\",\"must\",\"my\",\"neither\",\"no\",\"nor\",\"not\",\"of\",\"off\",\"often\",\"on\",\"only\",\"or\",\"other\",\"our\",\"own\",\"rather\",\"said\",\"say\",\"says\",\"she\",\"should\",\"since\",\"so\",\"some\",\"than\",\"that\",\"the\",\"their\",\"them\",\"then\",\"there\",\"these\",\"they\",\"this\",\"tis\",\"to\",\"too\",\"twas\",\"us\",\"wants\",\"was\",\"we\",\"were\",\"what\",\"when\",\"where\",\"which\",\"while\",\"who\",\"whom\",\"why\",\"will\",\"with\",\"would\",\"yet\",\"you\",\"your\",\"ain't\",\"aren't\",\"can't\",\"could've\",\"couldn't\",\"didn't\",\"doesn't\",\"don't\",\"hasn't\",\"he'd\",\"he'll\",\"he's\",\"how'd\",\"how'll\",\"how's\",\"i'd\",\"i'll\",\"i'm\",\"i've\",\"isn't\",\"it's\",\"might've\",\"mightn't\",\"must've\",\"mustn't\",\"shan't\",\"she'd\",\"she'll\",\"she's\",\"should've\",\"shouldn't\",\"that'll\",\"that's\",\"there's\",\"they'd\",\"they'll\",\"they're\",\"they've\",\"wasn't\",\"we'd\",\"we'll\",\"we're\",\"weren't\",\"what'd\",\"what's\",\"when'd\",\"when'll\",\"when's\",\"where'd\",\"where'll\",\"where's\",\"who'd\",\"who'll\",\"who's\",\"why'd\",\"why'll\",\"why's\",\"won't\",\"would've\",\"wouldn't\",\"you'd\",\"you'll\",\"you're\",\"you've\"]\n",
    "    vector = TfidfVectorizer(min_df=5, max_df = 0.75, sublinear_tf=True, stop_words = stopWords)\n",
    "    trainV = vector.fit_transform(trainData)\n",
    "    testV = vector.transform(testData)\n",
    "    return trainV, testV\n",
    "\n",
    "trainVectors, testVectors = buildDocumentTermMatrix(tweetTrainData, tweetTestData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Budowa klasyfikatora.\n",
    "\n",
    "Biblioteka scikit-learn udostępnia wiele algorytmów do budowania klasyfikatorów. \n",
    "Kod poniżej przedstawia użycie niektórych z nich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wyniki dla RandomForest\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.45      0.25      0.32       296\n",
      "    neutral       0.47      0.42      0.45       611\n",
      "   positive       0.61      0.75      0.68       837\n",
      "\n",
      "avg / total       0.54      0.55      0.54      1744\n",
      "\n",
      "Wyniki dla SVC\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.00      0.00      0.00       296\n",
      "    neutral       0.00      0.00      0.00       611\n",
      "   positive       0.48      1.00      0.65       837\n",
      "\n",
      "avg / total       0.23      0.48      0.31      1744\n",
      "\n",
      "Wynik dla LinearSVC()\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.52      0.21      0.30       296\n",
      "    neutral       0.48      0.45      0.46       611\n",
      "   positive       0.63      0.79      0.70       837\n",
      "\n",
      "avg / total       0.56      0.57      0.55      1744\n",
      "\n",
      "Wyniki dla BernoulliNB\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.45      0.30      0.36       296\n",
      "    neutral       0.51      0.41      0.45       611\n",
      "   positive       0.63      0.79      0.70       837\n",
      "\n",
      "avg / total       0.56      0.58      0.56      1744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "classifierRfc = rfc.fit(trainVectors, tweetTrainLabel)\n",
    "predictionRfc = rfc.predict(testVectors)\n",
    "\n",
    "print(\"Wyniki dla RandomForest\")\n",
    "print(classification_report(tweetTestLabel, predictionRfc))\n",
    "\n",
    "svc = svm.SVC()\n",
    "classifierSvc = svc.fit(trainVectors, tweetTrainLabel)\n",
    "predictionSvc = classifierSvc.predict(testVectors)\n",
    "\n",
    "print(\"Wyniki dla SVC\")\n",
    "print(classification_report(tweetTestLabel, predictionSvc))\n",
    "\n",
    "svcLinear = svm.SVC(kernel='linear')\n",
    "classifierSvcLinear = svcLinear.fit(trainVectors, tweetTrainLabel)\n",
    "predictionSvcLinear = classifierSvcLinear.predict(testVectors)\n",
    "\n",
    "print(\"Wynik dla LinearSVC()\")\n",
    "print(classification_report(tweetTestLabel, predictionSvcLinear))\n",
    "\n",
    "gnb = BernoulliNB()\n",
    "classifierGnb = gnb.fit(trainVectors, tweetTrainLabel)\n",
    "predictionGnb = classifierGnb.predict(testVectors)\n",
    "\n",
    "print(\"Wyniki dla BernoulliNB\")\n",
    "print(classification_report(tweetTestLabel, predictionGnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najlepszy wyniki osiągnął algorytm naiwnego Bayesa (BernoulliNB) i to on został wykorzystany do zbudowania ostatecznego klasyfikatora.\n",
    "\n",
    "## Podsumowanie\n",
    "\n",
    "Na sam koniec jako dane treningowe wczytano cały zbiór danych z pliku 'train.csv'. Został on przetworzony w taki sam sposób jak w powyższych krokach. Później używając algorytmu naiwnego Bayesa zbudowano model i dokonano predykcji atrybutu 'Category' dla danyh testowych pochodzących z pliku 'test.csv'. Rezultat został zapisany do pliku 'wynik.csv'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepareAndCleanTestData(tweets):\n",
    "    data = []\n",
    "    idArray = []\n",
    "    for index, tweet in tweets.iterrows():\n",
    "        tweet['Tweet'] = re.sub(r'@\\w+', '', tweet['Tweet'])\n",
    "        tweet['Tweet'] = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', tweet['Tweet'])\n",
    "        tweet['Tweet'] = re.sub(\"(:-?\\))|(:p)|(:d+)|(:-?\\()|(:/)|(;-?\\))|(<3)|(=\\))|(\\)-?:)|(:'\\()|(8\\))\", '', tweet['Tweet'])\n",
    "        data.append(tweet['Tweet'])\n",
    "        idArray.append(tweet['Id'])\n",
    "    return data, idArray\n",
    "\n",
    "tweetTrain = pd.read_csv(\"train.csv\",sep=',', header = 1, names=['Id','Category','Tweet'])\n",
    "tweetTest = pd.read_csv(\"test.csv\",sep=',', header = 0, names=['Id','Tweet'])\n",
    "\n",
    "tweetTrainData, tweetTrainLabel = prepareAndCleanData(tweetTrain) \n",
    "tweetTestData, tweetTestId = prepareAndCleanTestData(tweetTest)\n",
    "\n",
    "trainVectors, testVectors = buildDocumentTermMatrix(tweetTrainData, tweetTestData)\n",
    "\n",
    "gnb = BernoulliNB()\n",
    "classifierGnb = gnb.fit(trainVectors, tweetTrainLabel)\n",
    "predictionGnb = classifierGnb.predict(testVectors)\n",
    "\n",
    "data_temp = {'Id' : tweetTestId, 'Category' : predictionGnb }\n",
    "output = pd.DataFrame(data=data_temp)\n",
    "output.to_csv('wynik.csv',sep=',', index=False, columns=['Id','Category'])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
